# Text-Mining-With-Python

Every day, we generate huge amounts of text online, creating vast quantities of data about what is happening in the world and what people think. All of this text data is an invaluable resource that can be mined in order to generate meaningful business insights for analysts and organizations. However, analyzing all of this content isn’t easy, since converting text produced by people into structured information to analyze with a machine is a complex task. In recent years though, Natural Language Processing and Text Mining has become a lot more accessible for data scientists, analysts, and developers alike.

There is a massive amount of resources, code libraries, services, and APIs out there which can all help you embark on your first NLP project. For this how-to post, we thought we’d put together a three-step, end-to-end guide to your first introductory NLP project. I'll start from scratch by showing you how to build a corpus of language data and how to analyze this text, and then i’ll finish by visualizing the results.

I’ve split this post into 3 steps. Each of these steps will do two things: show a core task that will get you familiar with NLP basics, and also introduce you to some common APIs and code libraries for each of the tasks. The tasks I’ve selected are:

Building a corpus — using Tweepy to gather sample text data from Twitter’s API.
Analyzing text — analyzing the sentiment of a piece of text with our own SDK.
Visualizing results — how to use Pandas and matplotlib to see the results of your work.
